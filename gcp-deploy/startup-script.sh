#!/bin/bash
# GCP VM å•Ÿå‹•è…³æœ¬ - è‡ªå‹•å®‰è£ä¸¦é…ç½®å»ºç…§çˆ¬èŸ²

set -e

# æ—¥èªŒå‡½æ•¸
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a /var/log/crawler-setup.log
}

log "ðŸš€ é–‹å§‹è¨­å®šå»ºç…§çˆ¬èŸ²ç’°å¢ƒ..."

# æ›´æ–°ç³»çµ±
log "ðŸ“¦ æ›´æ–°ç³»çµ±å¥—ä»¶..."
apt-get update -y
apt-get upgrade -y

# å®‰è£å¿…è¦å¥—ä»¶
log "ðŸ“¦ å®‰è£å¿…è¦å¥—ä»¶..."
apt-get install -y \
    python3 \
    python3-pip \
    python3-venv \
    wget \
    curl \
    git \
    unzip \
    cron \
    supervisor \
    jq

# å®‰è£ Python å¥—ä»¶
log "ðŸ å®‰è£ Python å¥—ä»¶..."
pip3 install \
    requests \
    beautifulsoup4 \
    lxml \
    python-dateutil

# å®‰è£ OCI CLI
log "â˜ï¸ å®‰è£ OCI CLI..."
bash -c "$(curl -L https://raw.githubusercontent.com/oracle/oci-cli/master/scripts/install/install.sh)" -- --accept-all-defaults
export PATH="$PATH:/root/bin"
echo 'export PATH="$PATH:/root/bin"' >> /root/.bashrc

# å‰µå»ºå·¥ä½œç›®éŒ„
log "ðŸ“ å‰µå»ºå·¥ä½œç›®éŒ„..."
mkdir -p /opt/crawler
cd /opt/crawler

# ä¸‹è¼‰å°ˆæ¡ˆä»£ç¢¼
log "ðŸ“¥ ä¸‹è¼‰å°ˆæ¡ˆä»£ç¢¼..."
git clone -b gcp-deploy https://github.com/your-username/taichung-building-permits.git .

# è¨­å®š OCI é…ç½®ï¼ˆéœ€è¦ç”¨æˆ¶æä¾›ï¼‰
log "âš™ï¸ è¨­å®š OCI é…ç½®..."
mkdir -p /root/.oci
cat > /root/.oci/config << 'EOL'
[DEFAULT]
user=ocid1.user.oc1..your-user-ocid
fingerprint=your-fingerprint
tenancy=ocid1.tenancy.oc1..your-tenancy-ocid
region=ap-tokyo-1
key_file=/root/.oci/key.pem
EOL

# å‰µå»ºä½”ä½ç¬¦é‡‘é‘°æ–‡ä»¶ï¼ˆéœ€è¦ç”¨æˆ¶æ‰‹å‹•ä¸Šå‚³çœŸå¯¦é‡‘é‘°ï¼‰
log "ðŸ”‘ å‰µå»º OCI é‡‘é‘°ä½”ä½ç¬¦..."
cat > /root/.oci/key.pem << 'EOL'
# è«‹å°‡æ‚¨çš„ OCI ç§é‘°å…§å®¹æ”¾åœ¨é€™è£¡
# æ ¼å¼ï¼š
# -----BEGIN PRIVATE KEY-----
# [your-private-key-content]
# -----END PRIVATE KEY-----
EOL
chmod 600 /root/.oci/key.pem

# å‰µå»ºçˆ¬èŸ²æœå‹™è…³æœ¬
log "ðŸ¤– å‰µå»ºçˆ¬èŸ²æœå‹™..."
cat > /opt/crawler/crawler-service.py << 'EOL'
#!/usr/bin/env python3
"""
GCP çˆ¬èŸ²æœå‹™ - å®šæ™‚åŸ·è¡Œå»ºç…§çˆ¬å–
"""
import subprocess
import sys
import os
import json
from datetime import datetime

def log(message):
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print(f"[{timestamp}] {message}")

def run_crawler():
    """åŸ·è¡Œçˆ¬èŸ²"""
    log("ðŸš€ é–‹å§‹åŸ·è¡Œå»ºç…§çˆ¬èŸ²...")
    
    try:
        # åˆ‡æ›åˆ°çˆ¬èŸ²ç›®éŒ„
        os.chdir('/opt/crawler/oci')
        
        # æª¢æŸ¥ç•¶å‰æœ€æ–°åºè™Ÿ
        log("ðŸ“Š æª¢æŸ¥ç•¶å‰è³‡æ–™ç‹€æ…‹...")
        result = subprocess.run([
            '/root/bin/oci', 'os', 'object', 'get',
            '--namespace', 'nrsdi1rz5vl8',
            '--bucket-name', 'taichung-building-permits', 
            '--name', 'permits.json',
            '--file', '/tmp/current_permits.json'
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            log(f"âŒ ä¸‹è¼‰ç¾æœ‰è³‡æ–™å¤±æ•—: {result.stderr}")
            return False
        
        # è§£æžç•¶å‰æœ€æ–°åºè™Ÿ
        with open('/tmp/current_permits.json', 'r') as f:
            data = json.load(f)
            permits = data.get('permits', [])
            y114_permits = [p for p in permits if p.get('permitYear') == 114]
            
            if y114_permits:
                latest = max(y114_permits, key=lambda x: x.get('sequenceNumber', 0))
                current_seq = latest['sequenceNumber']
                log(f"ðŸ“ ç•¶å‰æœ€æ–°åºè™Ÿ: {current_seq} ({latest['permitNumber']})")
                start_seq = current_seq + 1
            else:
                log("âš ï¸ æœªæ‰¾åˆ°114å¹´è³‡æ–™ï¼Œå¾ž1é–‹å§‹çˆ¬å–")
                start_seq = 1
        
        # åŸ·è¡Œçˆ¬èŸ²ï¼ˆçˆ¬å–50ç­†æˆ–ç›´åˆ°ç©ºç™½ï¼‰
        log(f"ðŸ” é–‹å§‹å¾žåºè™Ÿ {start_seq} çˆ¬å–...")
        result = subprocess.run([
            'python3', 'simple-crawl.py', '114', str(start_seq), str(start_seq + 49)
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            log("âœ… çˆ¬èŸ²åŸ·è¡ŒæˆåŠŸ")
            log(f"ðŸ“„ è¼¸å‡º: {result.stdout}")
            return True
        else:
            log(f"âŒ çˆ¬èŸ²åŸ·è¡Œå¤±æ•—: {result.stderr}")
            return False
            
    except Exception as e:
        log(f"ðŸ’¥ çˆ¬èŸ²åŸ·è¡Œç•°å¸¸: {str(e)}")
        return False

if __name__ == "__main__":
    success = run_crawler()
    sys.exit(0 if success else 1)
EOL

chmod +x /opt/crawler/crawler-service.py

# å‰µå»º systemd æœå‹™
log "âš™ï¸ å‰µå»º systemd æœå‹™..."
cat > /etc/systemd/system/crawler.service << 'EOL'
[Unit]
Description=Taiwan Building Permit Crawler
After=network.target

[Service]
Type=oneshot
User=root
WorkingDirectory=/opt/crawler
ExecStart=/usr/bin/python3 /opt/crawler/crawler-service.py
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
EOL

# å‰µå»º cron ä»»å‹™
log "â° è¨­å®šå®šæ™‚ä»»å‹™..."
cat > /etc/cron.d/crawler << 'EOL'
# æ¯æ—¥ä¸Šåˆ8:00åŸ·è¡Œçˆ¬èŸ²
0 8 * * * root /bin/systemctl start crawler.service

# æ¯é€±æ—¥å‡Œæ™¨2:00å‚™ä»½
0 2 * * 0 root /opt/crawler/backup.sh
EOL

# å‰µå»ºå‚™ä»½è…³æœ¬
log "ðŸ’¾ å‰µå»ºå‚™ä»½è…³æœ¬..."
cat > /opt/crawler/backup.sh << 'EOL'
#!/bin/bash
# æ¯é€±å‚™ä»½è…³æœ¬

DATE=$(date +%Y%m%d)
BACKUP_DIR="/opt/crawler/backups"

mkdir -p $BACKUP_DIR

# ä¸‹è¼‰ç•¶å‰è³‡æ–™é€²è¡Œå‚™ä»½
/root/bin/oci os object get \
  --namespace nrsdi1rz5vl8 \
  --bucket-name taichung-building-permits \
  --name permits.json \
  --file "$BACKUP_DIR/permits_$DATE.json"

# åªä¿ç•™æœ€è¿‘30å¤©çš„å‚™ä»½
find $BACKUP_DIR -name "permits_*.json" -mtime +30 -delete

echo "[$(date)] å‚™ä»½å®Œæˆ: permits_$DATE.json"
EOL

chmod +x /opt/crawler/backup.sh

# å•Ÿç”¨æœå‹™
log "ðŸ”„ å•Ÿç”¨æœå‹™..."
systemctl daemon-reload
systemctl enable cron

# æ¸¬è©¦ OCI é€£æŽ¥ï¼ˆæœƒå¤±æ•—ï¼Œå› ç‚ºéœ€è¦çœŸå¯¦é‡‘é‘°ï¼‰
log "ðŸ”— æ¸¬è©¦ OCI é€£æŽ¥..."
/root/bin/oci os ns get || log "âš ï¸ OCI é€£æŽ¥å¤±æ•— - è«‹æ‰‹å‹•è¨­å®šé‡‘é‘°"

# å‰µå»ºç‹€æ…‹æª¢æŸ¥è…³æœ¬
log "ðŸ“Š å‰µå»ºç‹€æ…‹æª¢æŸ¥è…³æœ¬..."
cat > /opt/crawler/check-status.sh << 'EOL'
#!/bin/bash
echo "=== å»ºç…§çˆ¬èŸ²ç‹€æ…‹æª¢æŸ¥ ==="
echo "æ™‚é–“: $(date)"
echo "ç³»çµ±: $(uname -a)"
echo "Python: $(python3 --version)"
echo "OCI CLI: $(/root/bin/oci --version || echo 'æœªå®‰è£æˆ–é…ç½®éŒ¯èª¤')"
echo "ç£ç¢Ÿç©ºé–“: $(df -h / | tail -1)"
echo "è¨˜æ†¶é«”ä½¿ç”¨: $(free -h)"
echo "æœ€è¿‘çˆ¬èŸ²åŸ·è¡Œ:"
journalctl -u crawler --since "24 hours ago" | tail -10
echo "========================="
EOL

chmod +x /opt/crawler/check-status.sh

# è¨­å®šå®Œæˆ
log "âœ… å»ºç…§çˆ¬èŸ²ç’°å¢ƒè¨­å®šå®Œæˆï¼"
log "ðŸ“‹ å¾ŒçºŒæ­¥é©Ÿï¼š"
log "   1. SSH é€£æŽ¥åˆ°æ­¤å¯¦ä¾‹"
log "   2. ç·¨è¼¯ /root/.oci/config è¨­å®šæ‚¨çš„ OCI èªè­‰"
log "   3. å°‡æ‚¨çš„ç§é‘°å…§å®¹æ”¾å…¥ /root/.oci/key.pem"
log "   4. åŸ·è¡Œ /opt/crawler/check-status.sh æª¢æŸ¥ç‹€æ…‹"
log "   5. æ‰‹å‹•æ¸¬è©¦: python3 /opt/crawler/crawler-service.py"

# å‰µå»ºè¨­å®šæŒ‡å—
cat > /root/SETUP_GUIDE.txt << 'EOL'
å»ºç…§çˆ¬èŸ² GCP è¨­å®šæŒ‡å—
====================

1. ç·¨è¼¯ OCI é…ç½®:
   nano /root/.oci/config
   
2. è¨­å®š OCI ç§é‘°:
   nano /root/.oci/key.pem
   ï¼ˆè²¼ä¸Šæ‚¨çš„ OCI ç§é‘°å…§å®¹ï¼‰
   
3. æ¸¬è©¦é€£æŽ¥:
   /root/bin/oci os ns get
   
4. æ‰‹å‹•åŸ·è¡Œçˆ¬èŸ²æ¸¬è©¦:
   python3 /opt/crawler/crawler-service.py
   
5. æª¢æŸ¥æœå‹™ç‹€æ…‹:
   systemctl status crawler
   
6. æŸ¥çœ‹çˆ¬èŸ²æ—¥èªŒ:
   journalctl -u crawler -f
   
7. ç«‹å³åŸ·è¡Œçˆ¬èŸ²:
   systemctl start crawler.service

å®šæ™‚ä»»å‹™å·²è¨­å®šç‚ºæ¯æ—¥ä¸Šåˆ 8:00 è‡ªå‹•åŸ·è¡Œã€‚
EOL

log "ðŸ“– è¨­å®šæŒ‡å—å·²ä¿å­˜è‡³ /root/SETUP_GUIDE.txt"
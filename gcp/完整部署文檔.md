# 台中市建照爬蟲系統 - 完整部署文檔

## 系統架構總覽

### 1. 運算環境
- **執行平台**: Google Cloud Platform (GCP)
- **區域**: asia-east1-b (台灣)
- **實例類型**: e2-micro (免費額度)
- **作業系統**: Ubuntu 22.04 LTS
- **IP 位置**: 台灣 IP (解決封鎖問題)

### 2. 資料儲存
- **儲存服務**: Oracle Cloud Infrastructure (OCI) Object Storage
- **Namespace**: nrsdi1rz5vl8
- **Bucket**: taichung-building-permits
- **區域**: ap-tokyo-1
- **公開網址**: https://objectstorage.ap-tokyo-1.oraclecloud.com/n/nrsdi1rz5vl8/b/taichung-building-permits/o/index.html

### 3. 資料檔案結構
```
OCI Object Storage:
├── all_permits.json          # 所有建照資料
├── data/
│   └── crawl-logs.json      # 爬蟲執行記錄
├── index.html               # 網頁顯示介面
└── backups/                 # 備份檔案
    └── backup_YYYYMMDD.json
```

## 部署步驟

### 步驟 1: 建立 Google Cloud 實例

```bash
# 建立爬蟲實例（會自動安裝所有必要元件）
gcloud compute instances create taichung-crawler-gcp \
  --zone=asia-east1-b \
  --machine-type=e2-micro \
  --image-family=ubuntu-2204-lts \
  --image-project=ubuntu-os-cloud \
  --boot-disk-size=20GB \
  --metadata-from-file=startup-script=/tmp/gcp_oci_startup.sh \
  --tags=http-server \
  --project=taichung-crawler
```

### 步驟 2: 連線到實例

```bash
# SSH 連線
gcloud compute ssh taichung-crawler-gcp --zone=asia-east1-b

# 檢查爬蟲狀態
tail -f /home/crawler/crawler.log

# 檢查 cron 設定
crontab -l
```

### 步驟 3: 手動執行爬蟲（可選）

```bash
cd /home/crawler
python3 gcp_to_oci_crawler.py
```

## 爬蟲程式說明

### 核心功能
1. **智慧爬取**: 從最新序號開始，避免重複
2. **必要欄位解析**:
   - 樓層 (floors)
   - 棟數 (buildings/buildingCount)
   - 戶數 (units)
   - 總樓地板面積 (totalFloorArea)
   - 發照日期 (issueDate)
3. **錯誤處理**: 連續5筆空白或3次錯誤自動停止
4. **資料同步**: 自動上傳到 OCI Object Storage

### 執行排程
- **每日自動執行**: 早上 7:30 (台北時間)
- **執行方式**: Linux cron job
- **日誌位置**: /home/crawler/crawler.log

## OCI Object Storage 設定

### 認證資訊
- **User OCID**: ocid1.user.oc1..aaaaaaaabxuqfxbheexsxha7ewice2zidrcwnswzi3jnj7lyispvvd3fepuq
- **Tenancy OCID**: ocid1.tenancy.oc1..aaaaaaaatj2jclzf26lcsptdllggkodf4kvaj4gajrxtjngakmjl6smu3t6q
- **Region**: ap-tokyo-1
- **API Key**: 已內嵌在啟動腳本中

### 資料存取
- **JSON 資料**: `oci os object get --namespace nrsdi1rz5vl8 --bucket-name taichung-building-permits --name all_permits.json --file permits.json`
- **網頁介面**: 直接訪問公開網址查看

## 維護指令

### GCP 實例管理
```bash
# 列出實例
gcloud compute instances list --filter="name=taichung-crawler-gcp"

# 停止實例
gcloud compute instances stop taichung-crawler-gcp --zone=asia-east1-b

# 啟動實例
gcloud compute instances start taichung-crawler-gcp --zone=asia-east1-b

# 刪除實例
gcloud compute instances delete taichung-crawler-gcp --zone=asia-east1-b
```

### OCI 資料管理
```bash
# 下載所有建照資料
oci os object get --namespace nrsdi1rz5vl8 --bucket-name taichung-building-permits --name all_permits.json --file permits.json

# 查看爬蟲記錄
oci os object get --namespace nrsdi1rz5vl8 --bucket-name taichung-building-permits --name data/crawl-logs.json --file logs.json

# 列出所有檔案
oci os object list --namespace nrsdi1rz5vl8 --bucket-name taichung-building-permits
```

## 資料格式說明

### 建照資料格式 (all_permits.json)
```json
{
  "indexKey": "11410100100",
  "year": 114,
  "sequence": 1,
  "permitNumber": "114中都建字第00001號",
  "applicant": "某某建設股份有限公司",
  "address": "台中市西屯區文心路",
  "buildingSummary": "地上15層地下3層共1棟共60戶",
  "floors": 15,
  "buildings": 1,
  "buildingCount": 1,  // 相容舊版
  "units": 60,
  "totalFloorArea": 12345.67,
  "issueDate": "2025-01-15",
  "crawlTime": "2025-08-02T10:30:00"
}
```

### 爬蟲記錄格式 (crawl-logs.json)
```json
{
  "executionTime": "2025-08-02T07:30:00",
  "newRecords": 10,
  "totalRecords": 5237,
  "latestSequence": 1123,
  "source": "Google Cloud Taiwan"
}
```

## 網頁介面功能

### 主要功能
1. **統計資訊**: 顯示各年度建照數量
2. **搜尋功能**: 可搜尋建照號碼、申請人、地址
3. **資料表格**: 顯示最新100筆建照資料
4. **執行記錄**: 顯示最近5次爬蟲執行狀況

### 更新機制
- 每次爬蟲執行後自動更新
- 包含最新資料和執行時間
- 公開訪問，無需認證

## 費用估算

### Google Cloud
- **Compute Engine e2-micro**: 每月免費額度 744 小時
- **網路流量**: 每月 1GB 免費
- **預估費用**: $0 (在免費額度內)

### Oracle Cloud
- **Object Storage**: 前 10GB 免費
- **網路流量**: Always Free 額度
- **預估費用**: $0 (在免費額度內)

## 故障排除

### 問題 1: 爬蟲無法連線
- 檢查實例是否運行中
- 確認網路連線正常
- 查看錯誤日誌: `/home/crawler/crawler.log`

### 問題 2: 資料未更新
- 檢查 cron job 是否正常: `crontab -l`
- 手動執行爬蟲測試
- 確認 OCI 認證正確

### 問題 3: 網頁無法訪問
- 確認 OCI Object Storage 公開訪問設定
- 檢查檔案是否正確上傳
- 清除瀏覽器快取

## 聯絡資訊
如有問題，請查看：
- 爬蟲日誌: `/home/crawler/crawler.log`
- OCI 儲存狀態: OCI Console
- GCP 實例狀態: GCP Console
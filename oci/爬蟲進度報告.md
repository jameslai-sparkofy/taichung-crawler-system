# 台中市建照爬蟲進度報告

## 目前狀態 (2025-07-27)

### 已完成工作
1. **114年資料**：成功爬取 1098 筆（序號 00001-01098，只有 01099 失敗）
2. **113年資料**：已開始爬取，目前約有 60+ 筆
3. **系統功能**：
   - ✅ 監控網頁正常運作
   - ✅ HTML原檔備份功能
   - ✅ 正確的資料解析（樓層、棟數、戶數、日期轉換）
   - ✅ 列表視圖與篩選排序功能

### 待完成工作
1. **113年資料**：還需爬取約 2140 筆（總計 2201 筆）
2. **112年資料**：需爬取 2039 筆
3. **自動化部署**：設定 OCI Functions 每日 3:00 AM 自動爬取

## 資料統計
- **總資料量**：目前 1160+ 筆
- **監控網址**：https://objectstorage.ap-tokyo-1.oraclecloud.com/n/nrsdi1rz5vl8/b/taichung-building-permits/o/index.html

## 爬蟲執行方式

### 方式一：使用簡單爬蟲（推薦）
```bash
cd "/mnt/c/claude code/建照爬蟲/oci"

# 爬取113年剩餘資料（從第70筆開始，每次100筆）
python3 simple-crawler-113.py 70 170
python3 simple-crawler-113.py 171 270
python3 simple-crawler-113.py 271 370
# ... 依此類推

# 爬取112年資料
# 修改 simple-crawler-113.py 中的 year = 112，然後執行
python3 simple-crawler-112.py 1 100
python3 simple-crawler-112.py 101 200
# ... 依此類推
```

### 方式二：使用續傳爬蟲
```bash
# 爬取113年剩餘資料
python3 resume-crawler.py 113 70 500   # 從70爬到500
python3 resume-crawler.py 113 501 1000 # 從501爬到1000
python3 resume-crawler.py 113 1001 1500
python3 resume-crawler.py 113 1501 2201

# 爬取112年資料
python3 resume-crawler.py 112 1 500
python3 resume-crawler.py 112 501 1000
python3 resume-crawler.py 112 1001 1500
python3 resume-crawler.py 112 1501 2039
```

### 方式三：背景執行（Linux/WSL）
```bash
# 使用 nohup 背景執行
nohup python3 fast-batch-crawler.py > crawler.log 2>&1 &

# 或使用 screen/tmux
screen -S crawler
python3 fast-batch-crawler.py
# 按 Ctrl+A+D 離開 screen

# 查看進度
tail -f crawler.log
```

## 注意事項

1. **爬取速度**：每筆資料需要 3-5 秒（包含兩次訪問和等待時間）
2. **超時問題**：Claude 的命令執行有 2 分鐘限制，每次只能爬取約 20-30 筆
3. **網站限制**：台中市網站需要特殊的兩次訪問策略
4. **資料保存**：建議每 20-50 筆就保存一次，避免資料遺失

## 預估時間

- 113年剩餘資料（約2140筆）：約 2-3 小時
- 112年全部資料（2039筆）：約 2-3 小時
- **總計**：約 4-6 小時完成所有爬取工作

## 建議

1. 使用本地環境或雲端主機執行爬蟲，避免超時問題
2. 分批次執行，每批 100-200 筆
3. 定期檢查進度和資料完整性
4. 完成後設定 OCI Functions 自動化每日更新
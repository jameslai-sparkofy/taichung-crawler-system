#!/bin/bash

# æ­£ç¢ºçš„çˆ¬èŸ²ç­–ç•¥ - è™•ç†ç™»å…¥é é¢é‡å®šå‘
echo "ğŸš€ å°ä¸­å¸‚å»ºç…§çˆ¬èŸ² - æ­£ç¢ºç­–ç•¥ç‰ˆæœ¬"
echo "================================================"

BASE_URL="https://mcgbm.taichung.gov.tw/bupic/pages/queryInfoAction.do"
NAMESPACE="nrsdi1rz5vl8"
BUCKET="taichung-building-permits"

# å»ºç«‹å·¥ä½œç›®éŒ„
WORK_DIR="/tmp/crawler-correct-$$"
mkdir -p "$WORK_DIR"
cd "$WORK_DIR"

# å‡½æ•¸ï¼šçˆ¬å–å–®ä¸€å»ºç…§
crawl_permit() {
    local INDEX_KEY=$1
    local SUCCESS=0
    
    echo "ğŸ” çˆ¬å– INDEX_KEY: $INDEX_KEY"
    
    # ç¬¬ä¸€æ¬¡è¨ªå• - æœƒè¢«é‡å®šå‘åˆ°ç™»å…¥é é¢
    echo "   ç¬¬ä¸€æ¬¡è¨ªå•ï¼ˆå»ºç«‹ sessionï¼‰..."
    wget -q --save-cookies=cookies.txt --keep-session-cookies \
         --user-agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36" \
         -O "first_$INDEX_KEY.html" \
         "$BASE_URL?INDEX_KEY=$INDEX_KEY"
    
    # é‡è¦ï¼šç­‰å¾…ä¸€æ®µæ™‚é–“ï¼Œä¸è¦å¤ªå¿«
    echo "   ç­‰å¾… 3 ç§’..."
    sleep 3
    
    # ç¬¬äºŒæ¬¡è¨ªå• - ä½¿ç”¨ç›¸åŒçš„ cookiesï¼Œè¨ªå•åŸç¶²å€
    echo "   ç¬¬äºŒæ¬¡è¨ªå•ï¼ˆå–å¾—è³‡æ–™ï¼‰..."
    wget -q --load-cookies=cookies.txt --save-cookies=cookies.txt --keep-session-cookies \
         --user-agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36" \
         -O "page_$INDEX_KEY.html" \
         "$BASE_URL?INDEX_KEY=$INDEX_KEY"
    
    # æª¢æŸ¥æª”æ¡ˆå¤§å°
    FILE_SIZE=$(wc -c < "page_$INDEX_KEY.html" 2>/dev/null || echo 0)
    echo "   æª”æ¡ˆå¤§å°: $FILE_SIZE bytes"
    
    # åˆ†æå…§å®¹
    if [ -f "page_$INDEX_KEY.html" ] && [ $FILE_SIZE -gt 1000 ]; then
        # å˜—è©¦è½‰æ›ç·¨ç¢¼ï¼ˆå°ç£ç¶²ç«™å¯èƒ½ä½¿ç”¨ Big5ï¼‰
        iconv -f big5 -t utf-8 "page_$INDEX_KEY.html" 2>/dev/null > "page_$INDEX_KEY.utf8.html" || cp "page_$INDEX_KEY.html" "page_$INDEX_KEY.utf8.html"
        
        # æª¢æŸ¥å…§å®¹
        if grep -q "å»ºé€ åŸ·ç…§è™Ÿç¢¼" "page_$INDEX_KEY.utf8.html"; then
            echo "   âœ… æ‰¾åˆ°å»ºç…§è³‡æ–™!"
            
            # æå–å»ºç…§è™Ÿç¢¼ï¼ˆç°¡å–®æå–ï¼‰
            PERMIT_NO=$(grep -A2 "å»ºé€ åŸ·ç…§è™Ÿç¢¼" "page_$INDEX_KEY.utf8.html" | grep -oE ">[^<]+<" | sed 's/[><]//g' | grep -v "^$" | head -1)
            [ -n "$PERMIT_NO" ] && echo "      å»ºç…§è™Ÿç¢¼: $PERMIT_NO"
            
            # æå–èµ·é€ äºº
            APPLICANT=$(grep -A5 "èµ·é€ äºº" "page_$INDEX_KEY.utf8.html" | grep -A2 "å§“å" | grep -oE ">[^<]+<" | sed 's/[><]//g' | grep -v "^$" | grep -v "å§“å" | head -1)
            [ -n "$APPLICANT" ] && echo "      èµ·é€ äºº: $APPLICANT"
            
            # æå–åœ°è™Ÿ
            LAND_NO=$(grep -A2 "åœ°è™Ÿ" "page_$INDEX_KEY.utf8.html" | grep -oE ">[^<]+<" | sed 's/[><]//g' | grep -v "^$" | grep -v "åœ°è™Ÿ" | head -1)
            [ -n "$LAND_NO" ] && echo "      åœ°è™Ÿ: $LAND_NO"
            
            SUCCESS=1
            
            # ä¿å­˜æˆåŠŸçš„é é¢
            cp "page_$INDEX_KEY.utf8.html" "success_$INDEX_KEY.html"
            
        elif grep -q "â—‹â—‹â—‹ä»£è¡¨éºå¤±å€‹è³‡" "page_$INDEX_KEY.utf8.html"; then
            echo "   âš ï¸  å€‹è³‡å·²éºå¤±"
        elif grep -q "æŸ¥ç„¡ä»»ä½•è³‡è¨Š" "page_$INDEX_KEY.utf8.html"; then
            echo "   âŒ æŸ¥ç„¡è³‡æ–™"
        else
            echo "   â“ æœªçŸ¥ç‹€æ…‹ï¼ˆå¯èƒ½éœ€è¦å†æ¬¡å˜—è©¦ï¼‰"
            # ä¿å­˜ä¾›é™¤éŒ¯
            cp "page_$INDEX_KEY.utf8.html" "unknown_$INDEX_KEY.html"
        fi
    else
        echo "   âŒ ç„¡æ³•å–å¾—é é¢"
    fi
    
    return $SUCCESS
}

# é–‹å§‹çˆ¬å–
echo ""
echo "ğŸ“Š é–‹å§‹çˆ¬å–å»ºç…§è³‡æ–™..."
echo ""

# å¹´ä»½å’Œé¡å‹
YEAR=114
TYPE=1

# çˆ¬å–çµ±è¨ˆ
TOTAL_CRAWLED=0
SUCCESS_COUNT=0
CONSECUTIVE_FAILURES=0

# å¾åºè™Ÿ 1 é–‹å§‹çˆ¬å–
for SEQ in {1..20}; do
    INDEX_KEY=$(printf "%d%d%05d00" $YEAR $TYPE $SEQ)
    
    if crawl_permit "$INDEX_KEY"; then
        SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
        CONSECUTIVE_FAILURES=0
    else
        CONSECUTIVE_FAILURES=$((CONSECUTIVE_FAILURES + 1))
        
        # é€£çºŒå¤±æ•—å¤ªå¤šæ¬¡å°±åœæ­¢
        if [ $CONSECUTIVE_FAILURES -ge 10 ]; then
            echo ""
            echo "âš ï¸  é€£çºŒå¤±æ•— 10 æ¬¡ï¼Œåœæ­¢çˆ¬å–"
            break
        fi
    fi
    
    TOTAL_CRAWLED=$((TOTAL_CRAWLED + 1))
    
    # æ¯å€‹è«‹æ±‚ä¹‹é–“ç­‰å¾…ï¼Œé¿å…å¤ªé »ç¹
    echo "   ç­‰å¾… 2 ç§’å¾Œç¹¼çºŒ..."
    sleep 2
    echo ""
done

# çµ±è¨ˆçµæœ
echo "ğŸ“Š çˆ¬å–çµ±è¨ˆ:"
echo "   ç¸½çˆ¬å–æ•¸: $TOTAL_CRAWLED"
echo "   æˆåŠŸæ•¸é‡: $SUCCESS_COUNT"

# å¦‚æœæœ‰æˆåŠŸçš„è³‡æ–™ï¼Œå‰µå»ºçµæœæª”æ¡ˆ
if [ $SUCCESS_COUNT -gt 0 ]; then
    echo ""
    echo "ğŸ“ å‰µå»ºçµæœæª”æ¡ˆ..."
    
    TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%S.%3NZ")
    
    # å‰µå»ºç°¡å–®çš„çµæœ JSON
    cat > crawl-result.json << EOF
{
  "lastUpdate": "$TIMESTAMP",
  "crawlDate": "$(date +%Y-%m-%d)",
  "totalCrawled": $TOTAL_CRAWLED,
  "successCount": $SUCCESS_COUNT,
  "year": $YEAR,
  "strategy": "å…©æ¬¡è¨ªå•ç­–ç•¥ï¼ˆé–“éš”3ç§’ï¼‰"
}
EOF
    
    # ä¸Šå‚³çµæœ
    echo "ğŸ“¤ ä¸Šå‚³çµæœåˆ° OCI..."
    oci os object put \
        --namespace "$NAMESPACE" \
        --bucket-name "$BUCKET" \
        --name "data/crawl-strategy-test.json" \
        --file crawl-result.json \
        --content-type "application/json" \
        --force
    
    # ä¿å­˜æˆåŠŸç¯„ä¾‹
    if ls success_*.html >/dev/null 2>&1; then
        SAMPLE=$(ls success_*.html | head -1)
        echo ""
        echo "ğŸ’¾ ä¿å­˜æˆåŠŸç¯„ä¾‹åˆ°: /tmp/crawl-success-sample.html"
        cp "$SAMPLE" /tmp/crawl-success-sample.html
        
        # é¡¯ç¤ºç¯„ä¾‹å…§å®¹ç‰‡æ®µ
        echo ""
        echo "ğŸ“„ æˆåŠŸé é¢ç‰‡æ®µ:"
        grep -A5 "å»ºé€ åŸ·ç…§è™Ÿç¢¼" "$SAMPLE" | head -10
    fi
fi

# æ¸…ç†
cd /
rm -rf "$WORK_DIR"

echo ""
echo "ğŸ‰ çˆ¬èŸ²åŸ·è¡Œå®Œæˆ!"
echo "ç›£æ§ç¶²é : https://objectstorage.ap-tokyo-1.oraclecloud.com/n/$NAMESPACE/b/$BUCKET/o/index.html"
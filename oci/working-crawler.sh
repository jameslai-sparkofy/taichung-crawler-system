#!/bin/bash

# å·¥ä½œç‰ˆæœ¬çš„çˆ¬èŸ² - è™•ç† session å’Œé‡å®šå‘
echo "ğŸš€ å°ä¸­å¸‚å»ºç…§çˆ¬èŸ² - å·¥ä½œç‰ˆæœ¬"
echo "================================================"

BASE_URL="https://mcgbm.taichung.gov.tw/bupic/pages/queryInfoAction.do"
NAMESPACE="nrsdi1rz5vl8"
BUCKET="taichung-building-permits"

# å»ºç«‹å·¥ä½œç›®éŒ„
WORK_DIR="/tmp/crawler-work-$$"
mkdir -p "$WORK_DIR"
cd "$WORK_DIR"

# ä½¿ç”¨ wget è™•ç† cookies å’Œ session
echo "ğŸ”§ å»ºç«‹ session..."

# å…ˆè¨ªå•ä¸»é å»ºç«‹ session
wget -q --save-cookies=cookies.txt --keep-session-cookies \
     --user-agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36" \
     -O /dev/null \
     "https://mcgbm.taichung.gov.tw/bupic/"

sleep 1

# æ¸¬è©¦å¹¾å€‹å·²çŸ¥çš„ INDEX_KEY
echo ""
echo "ğŸ“Š é–‹å§‹çˆ¬å–å»ºç…§è³‡æ–™..."
echo ""

# æ¸¬è©¦çš„ INDEX_KEY åˆ—è¡¨
TEST_KEYS=(
    "11410005100"  # æ‚¨æä¾›çš„
    "11410000100"
    "11410001000"
    "11410010000"
    "11410050000"
)

SUCCESS_COUNT=0

for INDEX_KEY in "${TEST_KEYS[@]}"; do
    echo "ğŸ” çˆ¬å– INDEX_KEY: $INDEX_KEY"
    
    # ä½¿ç”¨å»ºç«‹çš„ session çˆ¬å–
    wget -q --load-cookies=cookies.txt --save-cookies=cookies.txt --keep-session-cookies \
         --user-agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36" \
         -O "page_$INDEX_KEY.html" \
         "$BASE_URL?INDEX_KEY=$INDEX_KEY"
    
    # æª¢æŸ¥æª”æ¡ˆå¤§å°
    FILE_SIZE=$(wc -c < "page_$INDEX_KEY.html" 2>/dev/null || echo 0)
    echo "   æª”æ¡ˆå¤§å°: $FILE_SIZE bytes"
    
    # å¦‚æœç¬¬ä¸€æ¬¡æ²’æˆåŠŸï¼Œå†è©¦ä¸€æ¬¡ï¼ˆåˆ·æ–°ï¼‰
    if [ $FILE_SIZE -lt 1000 ]; then
        echo "   é‡æ–°å˜—è©¦..."
        sleep 1
        wget -q --load-cookies=cookies.txt --save-cookies=cookies.txt --keep-session-cookies \
             --user-agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36" \
             --referer="$BASE_URL?INDEX_KEY=$INDEX_KEY" \
             -O "page_$INDEX_KEY.html" \
             "$BASE_URL?INDEX_KEY=$INDEX_KEY"
        
        FILE_SIZE=$(wc -c < "page_$INDEX_KEY.html" 2>/dev/null || echo 0)
        echo "   æ–°æª”æ¡ˆå¤§å°: $FILE_SIZE bytes"
    fi
    
    # åˆ†æå…§å®¹
    if [ -f "page_$INDEX_KEY.html" ] && [ $FILE_SIZE -gt 1000 ]; then
        # è½‰æ›ç·¨ç¢¼ä¸¦æª¢æŸ¥å…§å®¹
        iconv -f big5 -t utf-8 "page_$INDEX_KEY.html" 2>/dev/null > "page_$INDEX_KEY.utf8.html" || cp "page_$INDEX_KEY.html" "page_$INDEX_KEY.utf8.html"
        
        if grep -q "å»ºé€ åŸ·ç…§è™Ÿç¢¼" "page_$INDEX_KEY.utf8.html"; then
            echo "   âœ… æ‰¾åˆ°å»ºç…§è³‡æ–™!"
            
            # æå–å»ºç…§è™Ÿç¢¼
            PERMIT_NO=$(grep -oE 'å»ºé€ åŸ·ç…§è™Ÿç¢¼[^<]*<[^>]*>[^<]*<[^>]*>([^<]+)' "page_$INDEX_KEY.utf8.html" | sed 's/.*>\([^<]*\)$/\1/' | head -1)
            [ -n "$PERMIT_NO" ] && echo "   å»ºç…§è™Ÿç¢¼: $PERMIT_NO"
            
            SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
            
            # ä¿å­˜æˆåŠŸçš„é é¢
            cp "page_$INDEX_KEY.utf8.html" "success_$INDEX_KEY.html"
            
        elif grep -q "â—‹â—‹â—‹ä»£è¡¨éºå¤±å€‹è³‡" "page_$INDEX_KEY.utf8.html"; then
            echo "   âš ï¸  å€‹è³‡å·²éºå¤±"
        elif grep -q "æŸ¥ç„¡ä»»ä½•è³‡è¨Š" "page_$INDEX_KEY.utf8.html"; then
            echo "   âŒ æŸ¥ç„¡è³‡æ–™"
        else
            echo "   â“ æœªçŸ¥ç‹€æ…‹"
        fi
    else
        echo "   âŒ ç„¡æ³•å–å¾—é é¢"
    fi
    
    sleep 2
done

echo ""
echo "ğŸ“Š çˆ¬å–çµæœçµ±è¨ˆ:"
echo "   æ¸¬è©¦æ•¸é‡: ${#TEST_KEYS[@]}"
echo "   æˆåŠŸæ•¸é‡: $SUCCESS_COUNT"

# å¦‚æœæœ‰æˆåŠŸçš„é é¢ï¼Œå‰µå»ºç°¡å–®çš„è³‡æ–™æª”æ¡ˆ
if [ $SUCCESS_COUNT -gt 0 ]; then
    echo ""
    echo "ğŸ“ å‰µå»ºè³‡æ–™æª”æ¡ˆ..."
    
    TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%S.%3NZ")
    
    cat > crawl-result.json << EOF
{
  "lastUpdate": "$TIMESTAMP",
  "totalCrawled": ${#TEST_KEYS[@]},
  "successCount": $SUCCESS_COUNT,
  "message": "ä½¿ç”¨ wget æˆåŠŸçˆ¬å–å»ºç…§è³‡æ–™",
  "testedKeys": [
$(printf '    "%s"' "${TEST_KEYS[@]}" | sed 's/" "/",\n    "/g')
  ]
}
EOF
    
    # ä¸Šå‚³çµæœ
    echo "ğŸ“¤ ä¸Šå‚³çµæœåˆ° OCI..."
    oci os object put \
        --namespace "$NAMESPACE" \
        --bucket-name "$BUCKET" \
        --name "data/crawler-test-result.json" \
        --file crawl-result.json \
        --content-type "application/json" \
        --force
    
    # ä¿å­˜ä¸€å€‹æˆåŠŸçš„ç¯„ä¾‹
    if ls success_*.html >/dev/null 2>&1; then
        SAMPLE=$(ls success_*.html | head -1)
        echo ""
        echo "ğŸ’¾ ä¿å­˜æˆåŠŸç¯„ä¾‹åˆ°: /tmp/success-sample.html"
        cp "$SAMPLE" /tmp/success-sample.html
    fi
fi

# æ¸…ç†
cd /
rm -rf "$WORK_DIR"

echo ""
echo "ğŸ‰ çˆ¬èŸ²æ¸¬è©¦å®Œæˆ!"
echo "ç›£æ§ç¶²é : https://objectstorage.ap-tokyo-1.oraclecloud.com/n/$NAMESPACE/b/$BUCKET/o/index.html"
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import sys
sys.path.append('.')

# è¼‰å…¥çˆ¬èŸ²é¡åˆ¥
exec(open('optimized-crawler.py').read().split('if __name__ == "__main__":')[0])

# å»ºç«‹çˆ¬èŸ²å¯¦ä¾‹
crawler = OptimizedCrawler()
crawler.request_delay = 1.2  # ä¸¦ç™¼æ™‚å¢åŠ å»¶é²
crawler.batch_size = 20

print(f"ğŸ”§ Worker 2 å•Ÿå‹•")
print("=" * 70)

# ä»»å‹™åˆ—è¡¨
tasks = [(114, 1041, 1080)]

for task in tasks:
    year, start_seq, end_seq = task
    print(f"
ğŸ“ çˆ¬å– {year}å¹´ {start_seq:05d}-{end_seq:05d}...")
    try:
        crawler.crawl_year_range(year, start_seq, end_seq, False)
        print(f"âœ… å®Œæˆ {year}å¹´ {start_seq:05d}-{end_seq:05d}")
    except Exception as e:
        print(f"âŒ å¤±æ•— {year}å¹´ {start_seq:05d}-{end_seq:05d}: {e}")
        crawler.save_progress()

print(f"
ğŸ‰ Worker 2 æ‰€æœ‰ä»»å‹™å®Œæˆ")

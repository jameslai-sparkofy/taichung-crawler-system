#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import sys
sys.path.append('.')

# è¼‰å…¥çˆ¬èŸ²é¡åˆ¥
exec(open('optimized-crawler.py').read().split('if __name__ == "__main__":')[0])

# å»ºç«‹çˆ¬èŸ²å¯¦ä¾‹
crawler = OptimizedCrawler()
crawler.request_delay = 1.2  # ç¨å¾®å¢åŠ å»¶é²é¿å…ä¸¦ç™¼å•é¡Œ
crawler.batch_size = 20  # æ¸›å°‘æ‰¹æ¬¡å¤§å°é¿å…è¡çª

print(f"ğŸ”§ Worker 1: çˆ¬å– 114å¹´ 00881-01104")
print("=" * 70)

try:
    crawler.crawl_year_range(114, 881, 1104, False)
    print(f"
âœ… Worker 1 å®Œæˆä»»å‹™")
except Exception as e:
    print(f"
âŒ Worker 1 éŒ¯èª¤: {e}")
    crawler.save_progress()

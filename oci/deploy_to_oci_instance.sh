#!/bin/bash

# OCI Compute Instance éƒ¨ç½²è…³æœ¬
# å°‡çˆ¬èŸ²ç¨‹å¼éƒ¨ç½²åˆ° OCI VM ä¸¦è¨­å®šæ¯æ—¥ 7:30 åŸ·è¡Œ

echo "ğŸš€ é–‹å§‹éƒ¨ç½²çˆ¬èŸ²åˆ° OCI Compute Instance"
echo "=========================================="

# è¨­å®šè®Šæ•¸
INSTANCE_IP="168.138.213.65"
SSH_KEY_PATH="~/.ssh/id_rsa"  # è«‹ä¿®æ”¹ç‚ºä½ çš„ SSH é‡‘é‘°è·¯å¾‘
REMOTE_USER="opc"  # OCI é è¨­ä½¿ç”¨è€…åç¨±
REMOTE_DIR="/home/opc/taichung-building-crawler"

# æª¢æŸ¥ IP æ˜¯å¦å·²è¨­å®š
if [ "$INSTANCE_IP" = "<è«‹å¡«å…¥ä½ çš„ OCI Instance IP>" ]; then
    echo "âŒ è«‹å…ˆç·¨è¼¯æ­¤è…³æœ¬ï¼Œå¡«å…¥ä½ çš„ OCI Instance IP"
    echo "   ç·¨è¼¯ç¬¬ 9 è¡Œçš„ INSTANCE_IP è®Šæ•¸"
    exit 1
fi

# å»ºç«‹éƒ¨ç½²ç”¨çš„å£“ç¸®æª”
echo "ğŸ“¦ æº–å‚™éƒ¨ç½²æª”æ¡ˆ..."
tar -czf crawler_deploy.tar.gz \
    optimized-crawler-stable.py \
    cron_daily_crawler_v3.py \
    backup_current_data.py \
    sync_to_github.py \
    baojia_companies.json \
    daily_crawler_730am.sh

# ä¸Šå‚³åˆ°é ç«¯ä¼ºæœå™¨
echo "ğŸ“¤ ä¸Šå‚³æª”æ¡ˆåˆ° OCI Instance..."
scp -i "$SSH_KEY_PATH" crawler_deploy.tar.gz "$REMOTE_USER@$INSTANCE_IP:/tmp/"

# å»ºç«‹é ç«¯è¨­å®šè…³æœ¬
cat > remote_setup.sh << 'EOF'
#!/bin/bash

# åœ¨ OCI Instance ä¸ŠåŸ·è¡Œçš„è¨­å®šè…³æœ¬

echo "ğŸ”§ åœ¨ OCI Instance ä¸Šè¨­å®šçˆ¬èŸ²..."

# å®‰è£å¿…è¦å¥—ä»¶
echo "ğŸ“¦ å®‰è£ Python å¥—ä»¶..."
sudo yum install -y python3 python3-pip
pip3 install --user requests beautifulsoup4

# å®‰è£ OCI CLI (å¦‚æœé‚„æ²’å®‰è£)
if ! command -v oci &> /dev/null; then
    echo "ğŸ“¥ å®‰è£ OCI CLI..."
    bash -c "$(curl -L https://raw.githubusercontent.com/oracle/oci-cli/master/scripts/install/install.sh)" -- --accept-all-defaults
fi

# å»ºç«‹å·¥ä½œç›®éŒ„
mkdir -p ~/taichung-building-crawler
cd ~/taichung-building-crawler

# è§£å£“ç¸®æª”æ¡ˆ
tar -xzf /tmp/crawler_deploy.tar.gz

# è¨­å®šåŸ·è¡Œæ¬Šé™
chmod +x daily_crawler_730am.sh

# ä¿®æ”¹è…³æœ¬ä¸­çš„è·¯å¾‘
sed -i 's|/mnt/c/claude code/å»ºç…§çˆ¬èŸ²/oci|/home/opc/taichung-building-crawler|g' daily_crawler_730am.sh
sed -i 's|/home/laija/bin/oci|/home/opc/bin/oci|g' daily_crawler_730am.sh
sed -i 's|/home/laija/bin/oci|/home/opc/bin/oci|g' *.py

# è¨­å®š cron job
echo "â° è¨­å®š cron æ’ç¨‹..."
(crontab -l 2>/dev/null | grep -v "daily_crawler_730am.sh"; echo "30 7 * * * /home/opc/taichung-building-crawler/daily_crawler_730am.sh") | crontab -

# å»ºç«‹æ—¥èªŒç›®éŒ„
mkdir -p logs

# æ¸¬è©¦åŸ·è¡Œ
echo "ğŸ§ª æ¸¬è©¦çˆ¬èŸ²..."
python3 -c "import requests, bs4; print('âœ… Python å¥—ä»¶å·²å®‰è£')"

# é¡¯ç¤º cron è¨­å®š
echo ""
echo "âœ… éƒ¨ç½²å®Œæˆï¼"
echo "ğŸ“… Cron è¨­å®šï¼š"
crontab -l | grep daily_crawler
echo ""
echo "ğŸ’¡ æç¤ºï¼š"
echo "   - çˆ¬èŸ²å°‡åœ¨æ¯å¤©æ—©ä¸Š 7:30 è‡ªå‹•åŸ·è¡Œ"
echo "   - æ—¥èªŒæª”æ¡ˆ: ~/taichung-building-crawler/cron_daily_7am.log"
echo "   - æ‰‹å‹•åŸ·è¡Œ: ~/taichung-building-crawler/daily_crawler_730am.sh"

# æ¸…ç†æš«å­˜æª”
rm -f /tmp/crawler_deploy.tar.gz
EOF

# ä¸Šå‚³ä¸¦åŸ·è¡Œé ç«¯è¨­å®šè…³æœ¬
echo "ğŸš€ åŸ·è¡Œé ç«¯è¨­å®š..."
scp -i "$SSH_KEY_PATH" remote_setup.sh "$REMOTE_USER@$INSTANCE_IP:/tmp/"
ssh -i "$SSH_KEY_PATH" "$REMOTE_USER@$INSTANCE_IP" "bash /tmp/remote_setup.sh"

# æ¸…ç†æœ¬åœ°æª”æ¡ˆ
rm -f crawler_deploy.tar.gz remote_setup.sh

echo ""
echo "âœ… éƒ¨ç½²å®Œæˆï¼"
echo ""
echo "ğŸ“Œ å¾ŒçºŒç®¡ç†ï¼š"
echo "   1. SSH é€£ç·šåˆ° Instance:"
echo "      ssh -i $SSH_KEY_PATH $REMOTE_USER@$INSTANCE_IP"
echo ""
echo "   2. æŸ¥çœ‹çˆ¬èŸ²ç‹€æ…‹:"
echo "      ssh -i $SSH_KEY_PATH $REMOTE_USER@$INSTANCE_IP 'tail -f ~/taichung-building-crawler/cron_daily_7am.log'"
echo ""
echo "   3. æ‰‹å‹•åŸ·è¡Œçˆ¬èŸ²:"
echo "      ssh -i $SSH_KEY_PATH $REMOTE_USER@$INSTANCE_IP '~/taichung-building-crawler/daily_crawler_730am.sh'"
echo ""
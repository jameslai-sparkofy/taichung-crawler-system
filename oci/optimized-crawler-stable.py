#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å„ªåŒ–çˆ¬èŸ² - æ”¹è‰¯ç‰ˆ
ç­–ç•¥ï¼š
1. ä¸²è¡Œä½†å¿«é€Ÿ - æ¸›å°‘å»¶é²å’Œè¶…æ™‚æ™‚é–“
2. æ™ºèƒ½è·³é - å¿«é€Ÿæª¢æ¸¬ç„¡æ•ˆåºè™Ÿ
3. æ‰¹æ¬¡è™•ç† - æ¸›å°‘ä¸Šå‚³é »ç‡
4. éŒ¯èª¤æ¢å¾© - è‡ªå‹•é‡è©¦æ©Ÿåˆ¶
5. é€²åº¦ä¿å­˜ - ä¸­æ–·å¯æ¢å¾©
"""

import subprocess
import time
import json
import re
import os
import signal
import sys
from datetime import datetime

class OptimizedCrawler:
    def __init__(self):
        self.base_url = "https://mcgbm.taichung.gov.tw/bupic/pages/queryInfoAction.do"
        self.namespace = "nrsdi1rz5vl8"
        self.bucket_name = "taichung-building-permits"
        self.results = []
        self.failed_keys = []
        self.skipped_keys = []
        self.stats = {
            'total_attempted': 0,
            'successful': 0,
            'failed': 0,
            'skipped': 0,
            'start_time': time.time()
        }
        
        # å„ªåŒ–åƒæ•¸
        self.request_delay = 0.8  # æ¸›å°‘å»¶é²
        self.timeout = 20  # æ¸›å°‘è¶…æ™‚æ™‚é–“
        self.batch_size = 30  # å¢åŠ æ‰¹æ¬¡å¤§å°
        self.retry_limit = 2  # é‡è©¦æ¬¡æ•¸
        
        # è¨­å®šä¿¡è™Ÿè™•ç†
        signal.signal(signal.SIGINT, self.signal_handler)
        
    def signal_handler(self, signum, frame):
        """è™•ç†ä¸­æ–·ä¿¡è™Ÿ"""
        print(f"\nğŸ›‘ æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨ä¿å­˜é€²åº¦...")
        self.save_progress()
        self.print_final_stats()
        sys.exit(0)

    def crawl_single_permit(self, index_key, retry_count=0):
        """çˆ¬å–å–®ä¸€å»ºç…§è³‡æ–™ - å„ªåŒ–ç‰ˆ"""
        cookie_file = None
        temp_file = None
        
        try:
            # ä½¿ç”¨å”¯ä¸€çš„cookieæª”æ¡ˆé¿å…è¡çª
            cookie_file = f"/tmp/cookie_{index_key}_{int(time.time())}.txt"
            
            # ç¬¬ä¸€æ¬¡è¨ªå• - å»ºç«‹session
            cmd1 = [
                "wget", "-q", "--timeout=" + str(self.timeout),
                "--save-cookies=" + cookie_file, "--keep-session-cookies",
                "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "-O", "/dev/null",  # ç›´æ¥ä¸Ÿæ£„ç¬¬ä¸€æ¬¡å›æ‡‰
                f"{self.base_url}?INDEX_KEY={index_key}"
            ]
            
            result1 = subprocess.run(cmd1, capture_output=True, timeout=self.timeout)
            
            if result1.returncode != 0:
                self.cleanup_files(cookie_file)
                return None
            
            # çŸ­æš«å»¶é²
            time.sleep(self.request_delay)
            
            # ç¬¬äºŒæ¬¡è¨ªå• - å–å¾—è³‡æ–™
            temp_file = f"/tmp/page_{index_key}_{int(time.time())}.html"
            cmd2 = [
                "wget", "-q", "--timeout=" + str(self.timeout),
                "--load-cookies=" + cookie_file,
                "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "-O", temp_file,
                f"{self.base_url}?INDEX_KEY={index_key}"
            ]
            
            result2 = subprocess.run(cmd2, capture_output=True, timeout=self.timeout)
            
            # æ¸…ç†cookieæª”æ¡ˆ
            self.cleanup_files(cookie_file)
            
            if result2.returncode != 0:
                self.cleanup_files(temp_file)
                return None
            
            # è®€å–ä¸¦æª¢æŸ¥å…§å®¹
            try:
                with open(temp_file, 'rb') as f:
                    content = f.read()
                self.cleanup_files(temp_file)
            except:
                return None
            
            # å¿«é€Ÿæª¢æŸ¥å…§å®¹å¤§å°
            if len(content) < 1000:
                return None
            
            # è§£ç¢¼
            try:
                html = content.decode('big5')
            except:
                try:
                    html = content.decode('utf-8', errors='ignore')
                except:
                    return None
            
            # å¿«é€Ÿæª¢æŸ¥æ˜¯å¦æœ‰è³‡æ–™
            if "æŸ¥ç„¡ä»»ä½•è³‡è¨Š" in html:
                return "NO_DATA"  # ç‰¹æ®Šæ¨™è¨˜è¡¨ç¤ºæ­¤åºè™Ÿç„¡è³‡æ–™
            
            if "å»ºé€ åŸ·ç…§è™Ÿç¢¼" not in html:
                return None
            
            # è§£æè³‡æ–™
            permit_data = self.parse_permit_data(html, index_key)
            
            if permit_data:
                # èƒŒæ™¯ä¿å­˜HTML
                self.save_html_background(index_key, html)
                return permit_data
                
        except subprocess.TimeoutExpired:
            print(f"â° è¶…æ™‚ {index_key}")
            # åªæ¸…ç†å·²å®šç¾©çš„æª”æ¡ˆ
            if cookie_file:
                self.cleanup_files(cookie_file)
            if temp_file:
                self.cleanup_files(temp_file)
            return None
        except Exception as e:
            print(f"âŒ éŒ¯èª¤ {index_key}: {e}")
            # åªæ¸…ç†å·²å®šç¾©çš„æª”æ¡ˆ
            if cookie_file:
                self.cleanup_files(cookie_file)
            if temp_file:
                self.cleanup_files(temp_file)
            return None
        
        return None

    def cleanup_files(self, *files):
        """æ¸…ç†è‡¨æ™‚æª”æ¡ˆ"""
        for file_path in files:
            try:
                if os.path.exists(file_path):
                    os.unlink(file_path)
            except:
                pass

    def save_html_background(self, index_key, html_content):
        """èƒŒæ™¯ä¿å­˜HTML"""
        try:
            temp_file = f"/tmp/html_{index_key}_{int(time.time())}.html"
            with open(temp_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            # èƒŒæ™¯ä¸Šå‚³å‘½ä»¤
            cmd = f"""
            nohup oci os object put \\
                --namespace {self.namespace} \\
                --bucket-name {self.bucket_name} \\
                --name html/{index_key}.html \\
                --file {temp_file} \\
                --content-type 'text/html; charset=utf-8' \\
                --force && rm {temp_file} &
            """
            
            subprocess.Popen(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            
        except Exception as e:
            print(f"âš ï¸ HTMLä¿å­˜å¤±æ•— {index_key}: {e}")

    def parse_permit_data(self, html_content, index_key):
        """è§£æå»ºç…§è³‡æ–™"""
        try:
            permit_data = {
                'indexKey': index_key,
                'permitYear': int(index_key[:3]),
                'permitType': int(index_key[3]),
                'sequenceNumber': int(index_key[4:9]),
                'versionNumber': int(index_key[9:11]),
                'crawledAt': datetime.now().isoformat()
            }
            
            # å»ºç…§è™Ÿç¢¼ (å¿…è¦æ¬„ä½)
            m = re.search(r'<span class="conlist w20 tc">([1-9]\d{0,2}ä¸­[éƒ½å¸‚å»º]?å»ºå­—ç¬¬\d+è™Ÿ)</span>', html_content)
            if m:
                permit_data['permitNumber'] = m.group(1).strip()
            else:
                return None
            
            # èµ·é€ äºº
            patterns = [
                r'èµ·é€ äºº.*?å§“å.*?<span class="conlist w30">([^<]+)</span>',
                r'èµ·é€ äºº.*?<span class="conlist w30">([^<]+)</span>'
            ]
            for pattern in patterns:
                m = re.search(pattern, html_content, re.DOTALL)
                if m:
                    permit_data['applicantName'] = m.group(1).strip()
                    break
            
            # åœ°è™Ÿ
            m = re.search(r'åœ°è™Ÿ.*?<span class="conlist w30">([^<]+)</span>', html_content, re.DOTALL)
            if m:
                land_text = m.group(1).strip()
                permit_data['siteAddress'] = land_text
                
                # æå–è¡Œæ”¿å€
                district_match = re.search(r'è‡ºä¸­å¸‚([^å€]+å€)', land_text)
                if district_match:
                    permit_data['district'] = district_match.group(1)
            
            # å±¤æ£Ÿæˆ¶æ•¸
            m = re.search(r'å±¤æ£Ÿæˆ¶æ•¸.*?<span class="conlist w50">([^<]+)</span>', html_content, re.DOTALL)
            if m:
                floor_info = m.group(1).strip()
                permit_data['floorInfo'] = floor_info
                
                # è§£ææ•¸å€¼ - æ›´å®Œæ•´çš„è§£æ
                # åœ°ä¸Šå±¤æ•¸
                floor_match = re.search(r'åœ°ä¸Š(\d+)å±¤', floor_info)
                if floor_match:
                    permit_data['floorsAbove'] = int(floor_match.group(1))
                    permit_data['floors'] = int(floor_match.group(1))  # ä¿ç•™èˆŠæ¬„ä½ç›¸å®¹æ€§
                
                # åœ°ä¸‹å±¤æ•¸
                basement_match = re.search(r'åœ°ä¸‹(\d+)å±¤', floor_info)
                if basement_match:
                    permit_data['floorsBelow'] = int(basement_match.group(1))
                
                # å¹¢æ•¸
                block_match = re.search(r'(\d+)å¹¢', floor_info)
                if block_match:
                    permit_data['blockCount'] = int(block_match.group(1))
                
                # æ£Ÿæ•¸
                building_match = re.search(r'(\d+)æ£Ÿ', floor_info)
                if building_match:
                    permit_data['buildingCount'] = int(building_match.group(1))
                    permit_data['buildings'] = int(building_match.group(1))  # ç›¸å®¹èˆŠæ¬„ä½åç¨±
                
                # æˆ¶æ•¸
                unit_match = re.search(r'(\d+)æˆ¶', floor_info)
                if unit_match:
                    permit_data['unitCount'] = int(unit_match.group(1))
                    permit_data['units'] = int(unit_match.group(1))  # ç›¸å®¹èˆŠæ¬„ä½åç¨±
            
            # ç¸½æ¨“åœ°æ¿é¢ç©
            m = re.search(r'ç¸½æ¨“åœ°æ¿é¢ç©.*?<span class="conlist w50">([0-9.,]+)', html_content, re.DOTALL)
            if m:
                try:
                    area_str = m.group(1).replace(',', '')
                    permit_data['totalFloorArea'] = float(area_str)
                except:
                    pass
            
            # ç™¼ç…§æ—¥æœŸ
            m = re.search(r'ç™¼ç…§æ—¥æœŸ.*?<span class="conlist w30">(\d+å¹´\d+æœˆ\d+æ—¥)</span>', html_content, re.DOTALL)
            if m:
                date_text = m.group(1).strip()
                date_m = re.search(r'(\d+)å¹´(\d+)æœˆ(\d+)æ—¥', date_text)
                if date_m:
                    year = int(date_m.group(1))  # æ°‘åœ‹å¹´
                    month = int(date_m.group(2))
                    day = int(date_m.group(3))
                    # ä¿ç•™å…©ç¨®æ ¼å¼
                    permit_data['issueDate'] = f"{year + 1911:04d}-{month:02d}-{day:02d}"  # è¥¿å…ƒå¹´æ ¼å¼
                    permit_data['issueDateROC'] = f"{year:03d}/{month:02d}/{day:02d}"  # æ°‘åœ‹å¹´æ ¼å¼ 114/03/03
            
            return permit_data
            
        except Exception as e:
            print(f"âŒ è§£æå¤±æ•— {index_key}: {e}")
            return None

    def upload_batch_data(self, new_permits):
        """æ‰¹æ¬¡ä¸Šå‚³è³‡æ–™ - ç´¯åŠ æ¨¡å¼"""
        try:
            # å…ˆä¸‹è¼‰ç¾æœ‰è³‡æ–™
            existing_permits = []
            existing_data = {}
            
            print("   ğŸ“¥ è¼‰å…¥ç¾æœ‰è³‡æ–™...", end=' ')
            cmd = [
                "/home/laija/bin/oci", "os", "object", "get",
                "--namespace", self.namespace,
                "--bucket-name", self.bucket_name,
                "--name", "data/permits.json",
                "--file", "/tmp/existing_permits.json"
            ]
            
            result = subprocess.run(cmd, capture_output=True)
            
            if result.returncode == 0:
                try:
                    with open('/tmp/existing_permits.json', 'r', encoding='utf-8') as f:
                        existing_data = json.load(f)
                        existing_permits = existing_data.get('permits', [])
                    print(f"âœ… ({len(existing_permits)} ç­†)")
                except:
                    print("âš ï¸ (è®€å–å¤±æ•—)")
            else:
                print("âš ï¸ (ç„¡ç¾æœ‰è³‡æ–™)")
            
            # å»ºç«‹å·²å­˜åœ¨è³‡æ–™çš„å­—å…¸ï¼ˆç”¨æ–¼æ›´æ–°ï¼‰
            existing_dict = {p.get('indexKey'): p for p in existing_permits}
            
            # æ›´æ–°æˆ–æ–°å¢è³‡æ–™
            added_count = 0
            updated_count = 0
            
            for permit in new_permits:
                index_key = permit.get('indexKey')
                if index_key in existing_dict:
                    # æª¢æŸ¥ç¾æœ‰è³‡æ–™æ˜¯å¦å®Œæ•´
                    old_permit = existing_dict[index_key]
                    # å¦‚æœæ–°è³‡æ–™æœ‰æ›´å¤šæ¬„ä½ï¼Œå‰‡æ›´æ–°
                    if len(permit) > len(old_permit) or permit.get('crawledAt', '') > old_permit.get('crawledAt', ''):
                        existing_dict[index_key] = permit
                        updated_count += 1
                else:
                    # å…¨æ–°è³‡æ–™
                    existing_dict[index_key] = permit
                    added_count += 1
            
            # è½‰å›åˆ—è¡¨
            existing_permits = list(existing_dict.values())
            
            print(f"   â• æ–°å¢ {added_count} ç­†è³‡æ–™, ğŸ”„ æ›´æ–° {updated_count} ç­†è³‡æ–™")
            
            # æ’åºæ‰€æœ‰è³‡æ–™
            sorted_permits = sorted(existing_permits, key=lambda x: (
                -x.get('permitYear', 0),
                -x.get('sequenceNumber', 0)
            ))
            
            # çµ±è¨ˆå„å¹´ä»½æ•¸é‡
            year_counts = {}
            for permit in sorted_permits:
                year = permit.get('permitYear', 0)
                if year not in year_counts:
                    year_counts[year] = 0
                year_counts[year] += 1
            
            data = {
                "lastUpdate": datetime.now().isoformat(),
                "totalCount": len(sorted_permits),
                "yearCounts": year_counts,
                "permits": sorted_permits,
                "crawlStats": self.stats
            }
            
            # å¯«å…¥è‡¨æ™‚æª”æ¡ˆ
            temp_file = f"/tmp/permits_batch_{int(time.time())}.json"
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            # ä¸Šå‚³åˆ°ä¸‰å€‹ä½ç½®ï¼ˆåŒ…å«ç¶²é ä½¿ç”¨çš„all_permits.jsonï¼‰
            success = True
            for dest_path in ["permits.json", "data/permits.json", "all_permits.json"]:
                cmd = [
                    "/home/laija/bin/oci", "os", "object", "put",
                    "--namespace", self.namespace,
                    "--bucket-name", self.bucket_name,
                    "--name", dest_path,
                    "--file", temp_file,
                    "--content-type", "application/json",
                    "--force"
                ]
                result = subprocess.run(cmd, capture_output=True, timeout=60)
                if result.returncode != 0:
                    success = False
            
            os.unlink(temp_file)
            return success
            
        except Exception as e:
            print(f"âŒ æ‰¹æ¬¡ä¸Šå‚³å¤±æ•—: {e}")
            return False

    def save_progress(self):
        """ä¿å­˜é€²åº¦"""
        if self.results:
            print(f"ğŸ’¾ ä¿å­˜é€²åº¦ï¼š{len(self.results)} ç­†è³‡æ–™")
            self.upload_batch_data(self.results)

    def print_stats(self):
        """æ‰“å°å³æ™‚çµ±è¨ˆ"""
        elapsed = time.time() - self.stats['start_time']
        rate = self.stats['successful'] / elapsed if elapsed > 0 else 0
        
        print(f"ğŸ“Š [{elapsed:.0f}s] æˆåŠŸ:{self.stats['successful']} å¤±æ•—:{self.stats['failed']} è·³é:{self.stats['skipped']} é€Ÿåº¦:{rate:.2f}/s")

    def print_final_stats(self):
        """æ‰“å°æœ€çµ‚çµ±è¨ˆ"""
        elapsed = time.time() - self.stats['start_time']
        rate = self.stats['successful'] / elapsed if elapsed > 0 else 0
        
        print(f"\nğŸ æœ€çµ‚çµ±è¨ˆ:")
        print(f"   ç¸½è¨ˆå˜—è©¦: {self.stats['total_attempted']}")
        print(f"   æˆåŠŸ: {self.stats['successful']}")
        print(f"   å¤±æ•—: {self.stats['failed']}")
        print(f"   è·³é(ç„¡è³‡æ–™): {self.stats['skipped']}")
        print(f"   ç¸½è€—æ™‚: {elapsed:.1f} ç§’")
        print(f"   å¹³å‡é€Ÿåº¦: {rate:.2f} ç­†/ç§’")
        
        if self.stats['successful'] > 0:
            estimated_time = (5440 - self.stats['successful']) / rate / 3600  # é ä¼°å‰©é¤˜æ™‚é–“
            print(f"   é ä¼°å®Œæˆæ™‚é–“: {estimated_time:.1f} å°æ™‚")

    def crawl_year_range(self, year, start_seq, end_seq=None, auto_stop=False):
        """çˆ¬å–æŒ‡å®šå¹´ä»½ç¯„åœ
        
        Args:
            year: å¹´ä»½
            start_seq: é–‹å§‹åºè™Ÿ
            end_seq: çµæŸåºè™Ÿ (å¦‚æœç‚ºNoneä¸”auto_stop=Trueï¼Œå‰‡çˆ¬åˆ°ç©ºç™½ç‚ºæ­¢)
            auto_stop: æ˜¯å¦è‡ªå‹•åœæ­¢ï¼ˆé€£çºŒé‡åˆ°å¤šå€‹ç©ºç™½å¾Œåœæ­¢ï¼‰
        """
        if end_seq:
            print(f"ğŸš€ é–‹å§‹çˆ¬å– {year} å¹´è³‡æ–™ ({start_seq:05d}-{end_seq:05d})")
        else:
            print(f"ğŸš€ é–‹å§‹çˆ¬å– {year} å¹´è³‡æ–™ (å¾ {start_seq:05d} é–‹å§‹ï¼Œç›´åˆ°ç©ºç™½)")
        
        print(f"ğŸ”§ åƒæ•¸: å»¶é²={self.request_delay}s, è¶…æ™‚={self.timeout}s, æ‰¹æ¬¡={self.batch_size}")
        print("=" * 70)
        
        permit_type = 1
        consecutive_no_data = 0  # é€£çºŒç„¡è³‡æ–™è¨ˆæ•¸
        max_consecutive_no_data = 20  # é€£çºŒ20å€‹ç„¡è³‡æ–™å°±åœæ­¢
        consecutive_failed = 0  # é€£çºŒå¤±æ•—è¨ˆæ•¸
        max_consecutive_failed = 5  # é€£çºŒ5å€‹å¤±æ•—å°±åœæ­¢
        seq = start_seq
        
        while True:
            # å¦‚æœæœ‰è¨­å®šçµæŸåºè™Ÿä¸”å·²åˆ°é”ï¼Œå‰‡åœæ­¢
            if end_seq and seq > end_seq:
                break
                
            index_key = f"{year}{permit_type}{seq:05d}00"
            self.stats['total_attempted'] += 1
            
            print(f"ğŸ” [{seq:05d}] {index_key}...", end=' ', flush=True)
            
            result = self.crawl_single_permit(index_key)
            
            if result == "NO_DATA":
                # åºè™Ÿç„¡è³‡æ–™ï¼Œè·³é
                self.skipped_keys.append(index_key)
                self.stats['skipped'] += 1
                consecutive_no_data += 1
                consecutive_failed = 0  # ç„¡è³‡æ–™ä¸ç®—å¤±æ•—ï¼Œé‡ç½®å¤±æ•—è¨ˆæ•¸
                print(f"â­ï¸ ç„¡è³‡æ–™ (é€£çºŒ {consecutive_no_data})")
                
                # å¦‚æœå•Ÿç”¨è‡ªå‹•åœæ­¢ä¸”é€£çºŒç„¡è³‡æ–™è¶…éé–¾å€¼ï¼Œåœæ­¢çˆ¬å–
                if auto_stop and consecutive_no_data >= max_consecutive_no_data:
                    print(f"\nğŸ›‘ é€£çºŒ {max_consecutive_no_data} ç­†ç„¡è³‡æ–™ï¼Œåœæ­¢ {year} å¹´çˆ¬å–")
                    print(f"   æœ€å¾Œæœ‰æ•ˆåºè™Ÿç´„ç‚º: {seq - max_consecutive_no_data:05d}")
                    break
            elif result:
                # æˆåŠŸçˆ¬å–
                self.results.append(result)
                self.stats['successful'] += 1
                consecutive_no_data = 0  # é‡ç½®é€£çºŒç„¡è³‡æ–™è¨ˆæ•¸
                consecutive_failed = 0  # é‡ç½®é€£çºŒå¤±æ•—è¨ˆæ•¸
                print(f"âœ… {result['permitNumber']}")
            else:
                # çˆ¬å–å¤±æ•—
                self.failed_keys.append(index_key)
                self.stats['failed'] += 1
                consecutive_no_data = 0  # å¤±æ•—ä¹Ÿé‡ç½®è¨ˆæ•¸ï¼ˆå¯èƒ½æ˜¯ç¶²è·¯å•é¡Œï¼‰
                consecutive_failed += 1  # å¢åŠ é€£çºŒå¤±æ•—è¨ˆæ•¸
                print(f"âŒ å¤±æ•— (é€£çºŒ {consecutive_failed})")
                
                # å¦‚æœé€£çºŒå¤±æ•—è¶…éé–¾å€¼ï¼Œåœæ­¢çˆ¬å–
                if auto_stop and consecutive_failed >= max_consecutive_failed:
                    print(f"\nğŸ›‘ é€£çºŒ {max_consecutive_failed} æ¬¡å¤±æ•—ï¼Œåœæ­¢ {year} å¹´çˆ¬å–")
                    print(f"   æœ€å¾ŒæˆåŠŸåºè™Ÿç´„ç‚º: {seq - max_consecutive_failed:05d}")
                    break
            
            # æ¯10ç­†é¡¯ç¤ºçµ±è¨ˆ
            if self.stats['total_attempted'] % 10 == 0:
                self.print_stats()
            
            # æ‰¹æ¬¡ä¸Šå‚³
            if len(self.results) >= self.batch_size:
                print(f"\nğŸ’¾ æ‰¹æ¬¡ä¸Šå‚³ ({len(self.results)} ç­†)...", end=' ')
                if self.upload_batch_data(self.results):
                    print("âœ…")
                    self.results = []  # æ¸…ç©ºå·²ä¸Šå‚³çš„è³‡æ–™
                else:
                    print("âŒ")
            
            seq += 1
        
        # ä¸Šå‚³æœ€å¾Œå‰©é¤˜çš„è³‡æ–™
        if self.results:
            print(f"\nğŸ’¾ ä¸Šå‚³æœ€çµ‚è³‡æ–™ ({len(self.results)} ç­†)...")
            self.upload_batch_data(self.results)
        
        self.print_final_stats()

    def backup_existing_data(self):
        """å‚™ä»½ç¾æœ‰è³‡æ–™"""
        try:
            print("ğŸ“¦ å‚™ä»½ç¾æœ‰è³‡æ–™...")
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ä¸‹è¼‰ç¾æœ‰è³‡æ–™
            cmd = [
                "/home/laija/bin/oci", "os", "object", "get",
                "--namespace", self.namespace,
                "--bucket-name", self.bucket_name,
                "--name", "data/permits.json",
                "--file", f"/tmp/permits_backup_{timestamp}.json"
            ]
            
            result = subprocess.run(cmd, capture_output=True)
            
            if result.returncode == 0:
                # ä¸Šå‚³å‚™ä»½
                backup_cmd = [
                    "/home/laija/bin/oci", "os", "object", "put",
                    "--namespace", self.namespace,
                    "--bucket-name", self.bucket_name,
                    "--name", f"backups/permits_backup_{timestamp}.json",
                    "--file", f"/tmp/permits_backup_{timestamp}.json",
                    "--content-type", "application/json",
                    "--force"
                ]
                
                backup_result = subprocess.run(backup_cmd, capture_output=True)
                
                if backup_result.returncode == 0:
                    print(f"âœ… å‚™ä»½æˆåŠŸ: backups/permits_backup_{timestamp}.json")
                    # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                    os.unlink(f"/tmp/permits_backup_{timestamp}.json")
                    return True
                else:
                    print(f"âŒ å‚™ä»½ä¸Šå‚³å¤±æ•—")
                    return False
            else:
                print(f"âš ï¸ æ²’æœ‰ç¾æœ‰è³‡æ–™éœ€è¦å‚™ä»½")
                return True
                
        except Exception as e:
            print(f"âŒ å‚™ä»½å¤±æ•—: {e}")
            return False

def main():
    crawler = OptimizedCrawler()
    
    print("ğŸš€ å„ªåŒ–çˆ¬èŸ²å•Ÿå‹•ï¼")
    
    # å…ˆå‚™ä»½ç¾æœ‰è³‡æ–™
    crawler.backup_existing_data()
    
    # è¨­å®šçˆ¬å–è¨ˆç•« - 114å¹´çˆ¬åˆ°ç©ºç™½ç‚ºæ­¢ï¼Œå…¶ä»–å¹´ä»½æŒ‡å®šç¯„åœ
    crawl_plan = [
        (114, 401, None, True),   # 114å¹´ï¼šå¾401é–‹å§‹ï¼Œçˆ¬åˆ°ç©ºç™½ç‚ºæ­¢ï¼ˆæ¥çºŒä¹‹å‰çš„é€²åº¦ï¼‰
        (113, 1, 2201, False),    # 113å¹´ï¼š1-2201
        (112, 1, 2039, False),    # 112å¹´ï¼š1-2039
    ]
    
    print(f"\nğŸ“‹ çˆ¬å–è¨ˆç•«:")
    for item in crawl_plan:
        if len(item) == 4:
            year, start, end, auto_stop = item
            if auto_stop:
                print(f"   {year}å¹´: å¾ {start:05d} é–‹å§‹ï¼Œç›´åˆ°é€£çºŒç©ºç™½")
            else:
                count = end - start + 1
                print(f"   {year}å¹´: {start:05d}-{end:05d} ({count:,} ç­†)")
    
    print("=" * 70)
    
    # ä¾åºçˆ¬å–å„å¹´åº¦
    for item in crawl_plan:
        if len(item) == 4:
            year, start_seq, end_seq, auto_stop = item
        else:
            year, start_seq, end_seq = item
            auto_stop = False
            
        try:
            crawler.crawl_year_range(year, start_seq, end_seq, auto_stop)
            print(f"âœ… {year} å¹´çˆ¬å–å®Œæˆ\n")
        except KeyboardInterrupt:
            print(f"\nğŸ›‘ ç”¨æˆ¶ä¸­æ–· {year} å¹´çˆ¬å–")
            break
        except Exception as e:
            print(f"âŒ {year} å¹´çˆ¬å–ç•°å¸¸: {e}")
            crawler.save_progress()
            continue
    
    print("ğŸ‰ çˆ¬å–ä»»å‹™å®Œæˆï¼")

if __name__ == "__main__":
    # æª¢æŸ¥æ˜¯å¦ç‚ºè£œçˆ¬æ¨¡å¼
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "fill-gaps-114":
        # è£œçˆ¬114å¹´æ‰€æœ‰ç¼ºå¤±åºè™Ÿ
        crawler = OptimizedCrawler()
        crawler.request_delay = 0.5  # åŠ å¿«é€Ÿåº¦
        
        print("ğŸ”§ è£œçˆ¬114å¹´ç¼ºå¤±åºè™Ÿ")
        print("=" * 70)
        
        # 114å¹´çš„æ‰€æœ‰ç¼ºå¤±å€é–“
        gaps_114 = []
        # 101-344çš„è¦å¾‹æ€§ç¼ºå¤±ï¼ˆæ¯5å€‹ç¼º4å€‹ï¼‰
        for base in range(100, 345, 5):
            gaps_114.append((114, base+1, base+4))
        
        # 361-390çš„å¤§ç¼ºå£
        gaps_114.append((114, 361, 390))
        
        print(f"ğŸ“‹ ç¸½è¨ˆ {len(gaps_114)} çµ„ç¼ºå¤±å€é–“")
        
        for idx, (year, start, end) in enumerate(gaps_114):
            try:
                print(f"\n[{idx+1}/{len(gaps_114)}] è£œçˆ¬ {year}å¹´ {start:05d}-{end:05d}...")
                crawler.crawl_year_range(year, start, end, False)
            except KeyboardInterrupt:
                print("\nğŸ›‘ ç”¨æˆ¶ä¸­æ–·")
                break
            except Exception as e:
                print(f"âŒ å¤±æ•—: {e}")
                continue
        
        print("\nğŸ‰ 114å¹´è£œçˆ¬å®Œæˆï¼")
        
    elif len(sys.argv) > 1 and sys.argv[1] == "fill-gaps":
        crawler = OptimizedCrawler()
        
        print("ğŸ”§ è£œçˆ¬æ¼æ‰çš„è³‡æ–™")
        print("=" * 70)
        
        # éœ€è¦è£œçˆ¬çš„å€é–“
        gaps = [
            (114, 1, 99),      # 114å¹´ 1-99
            (114, 346, 360),   # 114å¹´ 346-360  
            (114, 391, 400),   # 114å¹´ 391-400
        ]
        
        print("ğŸ“‹ è£œçˆ¬è¨ˆç•«:")
        total_to_fill = 0
        for year, start, end in gaps:
            count = end - start + 1
            total_to_fill += count
            print(f"   {year}å¹´: {start:05d}-{end:05d} ({count} ç­†)")
        
        print(f"ğŸ“Š ç¸½è¨ˆéœ€è£œçˆ¬: {total_to_fill} ç­†")
        print("=" * 70)
        
        # ä¾åºè£œçˆ¬å„å€é–“
        for year, start_seq, end_seq in gaps:
            try:
                print(f"\nğŸ” è£œçˆ¬ {year}å¹´ {start_seq:05d}-{end_seq:05d}...")
                crawler.crawl_year_range(year, start_seq, end_seq, False)
                print(f"âœ… å€é–“ {start_seq:05d}-{end_seq:05d} å®Œæˆ")
            except KeyboardInterrupt:
                print(f"\nğŸ›‘ ç”¨æˆ¶ä¸­æ–·")
                break
            except Exception as e:
                print(f"âŒ è£œçˆ¬å¤±æ•—: {e}")
                crawler.save_progress()
                continue
        
        print("\nğŸ‰ è£œçˆ¬ä»»å‹™å®Œæˆï¼")
    else:
        main()
import logging
import os
from dotenv import load_dotenv
from building_permit_crawler import BuildingPermitCrawler
from database_manager import DatabaseManager

load_dotenv()

def setup_test_logging():
    """è¨­å®šæ¸¬è©¦æ—¥èªŒ"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('test_crawler.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

def test_database_connection():
    """æ¸¬è©¦è³‡æ–™åº«é€£æ¥"""
    print("æ¸¬è©¦è³‡æ–™åº«é€£æ¥...")
    db_manager = DatabaseManager()
    
    if db_manager.connect():
        print("âœ… è³‡æ–™åº«é€£æ¥æˆåŠŸ")
        db_manager.disconnect()
        return True
    else:
        print("âŒ è³‡æ–™åº«é€£æ¥å¤±æ•—")
        return False

def test_single_permit_crawl():
    """æ¸¬è©¦çˆ¬å–å–®ä¸€å»ºç…§"""
    print("æ¸¬è©¦çˆ¬å–å–®ä¸€å»ºç…§...")
    
    crawler = BuildingPermitCrawler()
    
    # æ¸¬è©¦å·²çŸ¥å­˜åœ¨çš„å»ºç…§
    test_index_key = "11410000100"
    
    try:
        if not crawler.db_manager.connect():
            print("âŒ ç„¡æ³•é€£æ¥è³‡æ–™åº«")
            return False
        
        success = crawler.crawl_single_permit(test_index_key)
        
        if success:
            print(f"âœ… æˆåŠŸçˆ¬å–å»ºç…§: {test_index_key}")
            return True
        else:
            print(f"âŒ çˆ¬å–å»ºç…§å¤±æ•—: {test_index_key}")
            return False
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False
    finally:
        crawler.db_manager.disconnect()

def test_index_key_generation():
    """æ¸¬è©¦INDEX_KEYç”Ÿæˆå’Œè§£æ"""
    print("æ¸¬è©¦INDEX_KEYç”Ÿæˆå’Œè§£æ...")
    
    crawler = BuildingPermitCrawler()
    
    # æ¸¬è©¦ç”Ÿæˆ
    year = 114
    permit_type = 1
    sequence = 1
    version = 0
    
    index_key = crawler.generate_index_key(year, permit_type, sequence, version)
    expected = "11410000100"
    
    if index_key == expected:
        print(f"âœ… INDEX_KEYç”Ÿæˆæ­£ç¢º: {index_key}")
    else:
        print(f"âŒ INDEX_KEYç”ŸæˆéŒ¯èª¤: æœŸæœ› {expected}, å¯¦éš› {index_key}")
        return False
    
    # æ¸¬è©¦è§£æ
    parsed = crawler.parse_index_key(index_key)
    
    if (parsed and 
        parsed['year'] == year and 
        parsed['permit_type'] == permit_type and
        parsed['sequence'] == sequence and
        parsed['version'] == version):
        print("âœ… INDEX_KEYè§£ææ­£ç¢º")
        return True
    else:
        print(f"âŒ INDEX_KEYè§£æéŒ¯èª¤: {parsed}")
        return False

def test_page_fetch():
    """æ¸¬è©¦é é¢ç²å–"""
    print("æ¸¬è©¦é é¢ç²å–...")
    
    crawler = BuildingPermitCrawler()
    test_index_key = "11410000100"
    
    try:
        response = crawler.fetch_page_with_retry(test_index_key)
        
        if response and response.status_code == 200:
            if 'å»ºç¯‰åŸ·ç…§è™Ÿç¢¼' in response.text:
                print("âœ… é é¢ç²å–æˆåŠŸä¸”åŒ…å«å»ºç…§è³‡æ–™")
                return True
            else:
                print("âŒ é é¢ç²å–æˆåŠŸä½†ä¸åŒ…å«å»ºç…§è³‡æ–™")
                return False
        else:
            print("âŒ é é¢ç²å–å¤±æ•—")
            return False
            
    except Exception as e:
        print(f"âŒ é é¢ç²å–æ¸¬è©¦ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

def test_small_batch_crawl():
    """æ¸¬è©¦å°æ‰¹é‡çˆ¬å–"""
    print("æ¸¬è©¦å°æ‰¹é‡çˆ¬å– (5ç­†è³‡æ–™)...")
    
    crawler = BuildingPermitCrawler()
    
    try:
        if not crawler.db_manager.connect():
            print("âŒ ç„¡æ³•é€£æ¥è³‡æ–™åº«")
            return False
        
        # é‡ç½®çµ±è¨ˆ
        crawler.total_crawled = 0
        crawler.new_records = 0
        crawler.error_records = 0
        
        # æ¸¬è©¦çˆ¬å–114å¹´å‰5å€‹ç·¨è™Ÿ
        for sequence in range(1, 6):
            index_key = crawler.generate_index_key(114, 1, sequence)
            success = crawler.crawl_single_permit(index_key)
            print(f"  ç·¨è™Ÿ {sequence}: {'æˆåŠŸ' if success else 'å¤±æ•—'}")
        
        print(f"âœ… å°æ‰¹é‡æ¸¬è©¦å®Œæˆ")
        print(f"   ç¸½çˆ¬å–: {crawler.total_crawled} ç­†")
        print(f"   æ–°å¢: {crawler.new_records} ç­†")
        print(f"   éŒ¯èª¤: {crawler.error_records} ç­†")
        
        return True
        
    except Exception as e:
        print(f"âŒ å°æ‰¹é‡çˆ¬å–æ¸¬è©¦ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False
    finally:
        crawler.db_manager.disconnect()

def main():
    """ä¸»æ¸¬è©¦ç¨‹åº"""
    setup_test_logging()
    
    print("ğŸš€ é–‹å§‹çˆ¬èŸ²ç³»çµ±æ¸¬è©¦")
    print("=" * 50)
    
    tests = [
        ("è³‡æ–™åº«é€£æ¥", test_database_connection),
        ("INDEX_KEYç”Ÿæˆå’Œè§£æ", test_index_key_generation),
        ("é é¢ç²å–", test_page_fetch),
        ("å–®ä¸€å»ºç…§çˆ¬å–", test_single_permit_crawl),
        ("å°æ‰¹é‡çˆ¬å–", test_small_batch_crawl),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ“‹ åŸ·è¡Œæ¸¬è©¦: {test_name}")
        try:
            if test_func():
                passed += 1
            else:
                print(f"âŒ {test_name} æ¸¬è©¦å¤±æ•—")
        except Exception as e:
            print(f"âŒ {test_name} æ¸¬è©¦ç™¼ç”Ÿç•°å¸¸: {e}")
        
        print("-" * 30)
    
    print(f"\nğŸ æ¸¬è©¦å®Œæˆ: {passed}/{total} é€šé")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼çˆ¬èŸ²ç³»çµ±æº–å‚™å°±ç·’")
    else:
        print("âš ï¸  éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥é…ç½®å’Œç’°å¢ƒ")

if __name__ == "__main__":
    main()